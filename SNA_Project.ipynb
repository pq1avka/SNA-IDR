{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmkuHAcZl9WK"
      },
      "source": [
        "### Hey!\n",
        "\n",
        "## Preamble\n",
        "\n",
        "1) Please while doing scraping for both capital letters and non-capital letters. for including typos such as ; \"terörist\" and \"terrörist\" let's scrap with letterwise instead of words wise.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnJFIZVUGn71"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_Tf4pXWl_bC"
      },
      "outputs": [],
      "source": [
        "scrapping_config = {\n",
        "    \"key_terms\": [\n",
        "      \"Hello\",\n",
        "      \"Anarşist\",\n",
        "      \"Terörist\",\n",
        "      \"Vatan haini\",\n",
        "      \"Gerilla\",\n",
        "      \"Ayyaş\",\n",
        "      \"Demokrasi düşmanı\",\n",
        "      \"Demokrasi karşıtı\",\n",
        "      \"Marjinal\",\n",
        "      \"Darbeci\",\n",
        "      \"Şiddet Yanlısı\",\n",
        "      \"Provokatör\",\n",
        "      \"Partizan\",\n",
        "      \"Polisler orantısız güç kullandı\",\n",
        "      \"Polis orantısız güç kullandı\",\n",
        "      \"Polis sert müdahalede bulundu\",\n",
        "      \"Polis sert müdahalede bulunmadı\",\n",
        "      \"Polis hayvanlara biber gazı sıktı\",\n",
        "      \"Polis çocuk öldürdü\",\n",
        "      \"Polis çocukları öldürdü\",\n",
        "      \"Darbe girişimi\",\n",
        "      \"Dijital darbe girişimi\",\n",
        "      \"İllegal terörizm\",\n",
        "      \"Terör Propogandası\",\n",
        "      \"Sivil toplum darbesi\",\n",
        "      \"sivil darbe\",\n",
        "      \"gezi parkının amacı istikrarı bozmak\",\n",
        "      \"terör örgütü\",\n",
        "      \"Provokatif Kışkırtma\",\n",
        "      \"hükümet düşecek\"\n",
        "    ],\n",
        "    \"main_usernames\": [\n",
        "      \"username1\",\n",
        "      \"username2\"\n",
        "    ]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QggYHM3rmZYP"
      },
      "outputs": [],
      "source": [
        "# Install twint actual library to virtual inviroment\n",
        "%pip uninstall twint -y\n",
        "%pip install --upgrade git+https://github.com/twintproject/twint.git@origin/master#egg=twint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FvH8vaetUTaN"
      },
      "outputs": [],
      "source": [
        "# Fix colab asyncio loops\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scrapping_config['key_terms'][17::]"
      ],
      "metadata": {
        "id": "ddjRnd43HS5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JW94qR6zURN3"
      },
      "outputs": [],
      "source": [
        "import twint\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize configs\n",
        "c = twint.Config()\n",
        "\n",
        "#c.Pandas = True # enable storing our scrapped tweets to pandas dataframes https://pandas.pydata.org\n",
        "c.Store_csv = True\n",
        "c.Retweets = True\n",
        "c.Pandas = True\n",
        "c.Lang = 'tr'\n",
        "c.Hide_output = True\n",
        "#c.Output = f'simple_{kt}.csv'\n",
        "c.Since = '2013-01-01'\n",
        "c.Until = '2013-12-31'\n",
        "\n",
        "for kt in scrapping_config['key_terms']:\n",
        "  c.Search = kt.lower()\n",
        "  c.Retries_count = 2\n",
        "  twint.run.Search(c) # run scrapping proccess\n",
        "  tweets_df = twint.storage.panda.Tweets_df.copy()\n",
        "  rtr = 1\n",
        "  while rtr < 50:\n",
        "    twint.run.Search(c) # run scrapping proccess\n",
        "    tweets_df = tweets_df.append(twint.storage.panda.Tweets_df.copy()) # storing tweets to pandas dataframe\n",
        "    rtr += 1\n",
        "    print(kt, rtr, len(tweets_df))\n",
        "  \n",
        "  tweets_df = tweets_df.drop_duplicates(subset=['id'])\n",
        "  tweets_df.to_csv(f'pd_{len(tweets_df)}_{kt}.csv')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "SNA Project",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}